# Training configuration for dots.ocr

# Data configuration
data:
  train_data: "./training_data.jsonl"
  eval_data: "./eval_data.jsonl"  # Optional
  max_seq_length: 8192
  max_image_pixels: 11289600

# Model configuration
model:
  model_name_or_path: "./weights/DotsOCR"
  trust_remote_code: true
  torch_dtype: "bfloat16"

# Training strategy
training_strategy:
  freeze_vision_encoder: false  # Set to true to freeze vision components
  freeze_llm: false            # Set to true to freeze language model
  lora_training: false         # Set to true for LoRA fine-tuning
  lora_rank: 8
  lora_alpha: 32

# Training hyperparameters
training:
  num_train_epochs: 3
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 2e-5
  weight_decay: 0.01
  warmup_steps: 100
  lr_scheduler_type: "linear"

# Optimization
optimization:
  fp16: false
  bf16: true
  gradient_checkpointing: true
  dataloader_num_workers: 4

# Logging and saving
logging:
  logging_steps: 10
  save_steps: 500
  eval_steps: 500
  save_total_limit: 3
  report_to: "wandb"  # Options: "wandb", "tensorboard", null
  run_name: "dots-ocr-training"

# Output
output:
  output_dir: "./checkpoints"
  overwrite_output_dir: true

# Evaluation
evaluation:
  evaluation_strategy: "steps"  # "steps" or "epoch"
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  load_best_model_at_end: true